{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f002d579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d4ae0b",
   "metadata": {},
   "source": [
    "# 1.Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22707757",
   "metadata": {},
   "source": [
    "In this notebook, we want to provide a tutorial about how to make inference using HugeCTR trained WDL model. And we can collect the inference benchmark by Triton performance analyzer tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2392df",
   "metadata": {},
   "source": [
    "1. Overview\n",
    "2. Generate the WDL deployment Configuration\n",
    "3. Load Models on the Triton Server\n",
    "4. Prepare Inference Input Data \n",
    "5. Inference Benchmarm by Triton Performance Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bc0f17",
   "metadata": {},
   "source": [
    "# 2. Generate the WDL Deployment Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f78f7f",
   "metadata": {},
   "source": [
    "## 2.1 Generate related model folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36e9b291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some data folder to store the model related files\n",
    "# Standard Libraries\n",
    "import os\n",
    "from time import time\n",
    "import re\n",
    "import shutil\n",
    "import glob\n",
    "import warnings\n",
    "\n",
    "BASE_DIR = \"/wdl_infer\"\n",
    "model_folder  = os.path.join(BASE_DIR, \"model\")\n",
    "wdl_model_repo= os.path.join(model_folder, \"wdl\")\n",
    "wdl_version =os.path.join(wdl_model_repo, \"1\")\n",
    "\n",
    "if os.path.isdir(model_folder):\n",
    "    shutil.rmtree(model_folder)\n",
    "os.makedirs(model_folder)\n",
    "\n",
    "if os.path.isdir(wdl_model_repo):\n",
    "    shutil.rmtree(wdl_model_repo)\n",
    "os.makedirs(wdl_model_repo)\n",
    "\n",
    "if os.path.isdir(wdl_version):\n",
    "    shutil.rmtree(wdl_version)\n",
    "os.makedirs(wdl_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b652a705",
   "metadata": {},
   "source": [
    "## 2.2 Copy WDL model files and configuration to model repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10e25ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4098\r\n",
      "-rw-r--r-- 1 root root    3731 Nov 30 06:01 wdl.json\r\n",
      "drwxr-xr-x 2 root root    4096 Nov 30 06:01 wdl0_sparse_20000.model\r\n",
      "drwxr-xr-x 2 root root    4096 Nov 30 06:01 wdl1_sparse_20000.model\r\n",
      "-rw-r--r-- 1 root root 5963780 Nov 30 06:01 wdl_dense_20000.model\r\n"
     ]
    }
   ],
   "source": [
    "!cp -r /wdl_train/wdl0_sparse_20000.model $wdl_version/\n",
    "!cp -r /wdl_train/wdl1_sparse_20000.model $wdl_version/\n",
    "!cp  /wdl_train/wdl_dense_20000.model $wdl_version/\n",
    "!cp /wdl_train/wdl.json $wdl_version/\n",
    "!ls -l $wdl_version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc99a23e",
   "metadata": {},
   "source": [
    "## 2.3 Generate the Triton configuration for deploying WDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "352f61ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /wdl_infer/model/wdl/config.pbtxt\n"
     ]
    }
   ],
   "source": [
    "%%writefile $wdl_model_repo/config.pbtxt\n",
    "name: \"wdl\"\n",
    "backend: \"hugectr\"\n",
    "max_batch_size:64,\n",
    "input [\n",
    "  {\n",
    "    name: \"DES\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ -1 ]\n",
    "  },\n",
    "  {\n",
    "    name: \"CATCOLUMN\"\n",
    "    data_type: TYPE_INT64\n",
    "    dims: [ -1 ]\n",
    "  },\n",
    "  {\n",
    "    name: \"ROWINDEX\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [ -1 ]\n",
    "  }\n",
    "]\n",
    "output [\n",
    "  {\n",
    "    name: \"OUTPUT0\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ -1 ]\n",
    "  }\n",
    "]\n",
    "instance_group [\n",
    "  {\n",
    "    count: 1\n",
    "    kind : KIND_GPU\n",
    "    gpus:[0]\n",
    "  }\n",
    "]\n",
    "\n",
    "parameters [\n",
    "  {\n",
    "    key: \"config\"\n",
    "    value: { string_value: \"/wdl_infer/model/wdl/1/wdl.json\" }\n",
    "  },\n",
    "  {\n",
    "    key: \"gpucache\"\n",
    "    value: { string_value: \"true\" }\n",
    "  },\n",
    "  {\n",
    "    key: \"hit_rate_threshold\"\n",
    "    value: { string_value: \"0.9\" }\n",
    "  },\n",
    "  {\n",
    "    key: \"gpucacheper\"\n",
    "    value: { string_value: \"0.5\" }\n",
    "  },\n",
    "  {\n",
    "    key: \"label_dim\"\n",
    "    value: { string_value: \"1\" }\n",
    "  },\n",
    "  {\n",
    "    key: \"slots\"\n",
    "    value: { string_value: \"28\" }\n",
    "  },\n",
    "  {\n",
    "    key: \"cat_feature_num\"\n",
    "    value: { string_value: \"28\" }\n",
    "  },\n",
    "  {\n",
    "    key: \"des_feature_num\"\n",
    "    value: { string_value: \"13\" }\n",
    "  },\n",
    "  {\n",
    "    key: \"max_nnz\"\n",
    "    value: { string_value: \"2\" }\n",
    "  },\n",
    "  {\n",
    "    key: \"embedding_vector_size\"\n",
    "    value: { string_value: \"128\" }\n",
    "  },\n",
    "  {\n",
    "    key: \"embeddingkey_long_type\"\n",
    "    value: { string_value: \"true\" }\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e917cd4",
   "metadata": {},
   "source": [
    "## 2.4 Configure a RocksDB directory for localized storage\n",
    "Make sure the RocksDB directory has read and write permissions for storing model embedded tables. Since we have created the RocksDB folder outside the container, please make sure to mount the correct folder path to /wdl_infer/rocksdb and configure the correct RocksDB path to the ps.json in the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213b02e9",
   "metadata": {},
   "source": [
    "## 2.5 Generate the Hugectr Backend parameter server configuration for deploying wdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98c2d820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /wdl_infer/model/ps.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile /wdl_infer/model/ps.json\n",
    "{\n",
    "    \"supportlonglong\":true,\n",
    "    \"volatile_db\": {\n",
    "        \"type\": \"disabled\",\n",
    "        \"address\": \"127.0.0.1:7000,127.0.0.1:7001,127.0.0.1:7002\",\n",
    "        \"user_name\": \"default\",\n",
    "        \"password\": \"\",\n",
    "        \"num_partitions\": 8,\n",
    "        \"max_get_batch_size\": 100000,\n",
    "        \"max_set_batch_size\": 100000,\n",
    "        \"overflow_policy\": \"evict_oldest\",\n",
    "        \"overflow_margin\": 10000000,\n",
    "        \"overflow_resolution_target\": 0.8,\n",
    "        \"initial_cache_rate\": 1.0,\n",
    "        \"update_filters\": [ \".+\" ]\n",
    "    },\n",
    "    \"persistent_db\": {\n",
    "        \"type\": \"rocksdb\",\n",
    "        \"path\": \"/wdl_infer/rocksdb\",\n",
    "        \"num_threads\": 16,\n",
    "        \"read_only\": false,\n",
    "        \"max_get_batch_size\": 10000,\n",
    "        \"max_set_batch_size\": 10000,\n",
    "        \"update_filters\": [ \".+\" ]\n",
    "    },\n",
    "    \"update_source\": {\n",
    "        \"type\": \"kafka\",\n",
    "        \"brokers\": \"127.0.0.1:9092\",\n",
    "        \"poll_timeout_ms\": 500,\n",
    "        \"max_receive_buffer_size\": 2000,\n",
    "        \"max_batch_size\": 1000,\n",
    "        \"failure_backoff_ms\": 50\n",
    "    },\n",
    "    \"models\":[\n",
    "        {\n",
    "            \"model\":\"wdl\",\n",
    "            \"sparse_files\":[\"/wdl_infer/model/wdl/1/wdl0_sparse_20000.model\", \"/wdl_infer/model/wdl/1/wdl1_sparse_20000.model\"],\n",
    "            \"dense_file\":\"/wdl_infer/model/wdl/1/wdl_dense_20000.model\",\n",
    "            \"network_file\":\"/wdl_infer/model/wdl/1/wdl.json\",\n",
    "            \"num_of_worker_buffer_in_pool\": \"4\",\n",
    "            \"num_of_refresher_buffer_in_pool\": \"1\",\n",
    "            \"deployed_device_list\":[\"0\"],\n",
    "            \"max_batch_size\":\"64\",\n",
    "            \"default_value_for_each_table\":[\"0.0\",\"0.0\"],\n",
    "            \"hit_rate_threshold\":\"0.9\",\n",
    "            \"gpucacheper\":\"0.5\",\n",
    "            \"gpucache\":\"true\",\n",
    "            \"cache_refresh_percentage_per_iteration\": 0.2\n",
    "        }\n",
    "    ]  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5db97930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1\n",
      "drwxr-xr-x 4 root root 4096 Nov 30 06:01 1\n",
      "-rw-r--r-- 1 root root 1174 Nov 30 06:03 config.pbtxt\n",
      "total 5858\n",
      "-rw-r--r-- 1 root root    3731 Nov 30 06:01 wdl.json\n",
      "drwxr-xr-x 2 root root    4096 Nov 30 06:01 wdl0_sparse_20000.model\n",
      "drwxr-xr-x 2 root root    4096 Nov 30 06:01 wdl1_sparse_20000.model\n",
      "-rw-r--r-- 1 root root 5963780 Nov 30 06:01 wdl_dense_20000.model\n"
     ]
    }
   ],
   "source": [
    "!ls -l $wdl_model_repo\n",
    "!ls -l $wdl_version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3a47dc",
   "metadata": {},
   "source": [
    "# 3.Deploy WDL on Triton Server "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de8db3e",
   "metadata": {},
   "source": [
    "At this stage, you should have already launched the Triton Inference Server with the following command:\n",
    "\n",
    "In this tutorial, we will deploy the Wide&Deep to a single A100(32GB),\n",
    "\n",
    "Note: `Since Background processes not supported by Jupyter, please launch the Triton Server according to the following command independently in the background.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5624d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I1130 06:27:18.632682 2794 metrics.cc:290] Collecting metrics for GPU 0: Tesla V100-SXM2-16GB\n",
      "I1130 06:27:18.632894 2794 metrics.cc:290] Collecting metrics for GPU 1: Tesla V100-SXM2-16GB\n",
      "I1130 06:27:18.632913 2794 metrics.cc:290] Collecting metrics for GPU 2: Tesla V100-SXM2-16GB\n",
      "I1130 06:27:18.632928 2794 metrics.cc:290] Collecting metrics for GPU 3: Tesla V100-SXM2-16GB\n",
      "I1130 06:27:18.632940 2794 metrics.cc:290] Collecting metrics for GPU 4: Tesla V100-SXM2-16GB\n",
      "I1130 06:27:18.632954 2794 metrics.cc:290] Collecting metrics for GPU 5: Tesla V100-SXM2-16GB\n",
      "I1130 06:27:18.632965 2794 metrics.cc:290] Collecting metrics for GPU 6: Tesla V100-SXM2-16GB\n",
      "I1130 06:27:18.632979 2794 metrics.cc:290] Collecting metrics for GPU 7: Tesla V100-SXM2-16GB\n",
      "I1130 06:27:18.860860 2794 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f0976000000' with size 268435456\n",
      "I1130 06:27:18.872084 2794 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864\n",
      "I1130 06:27:18.872095 2794 cuda_memory_manager.cc:105] CUDA memory pool is created on device 1 with size 67108864\n",
      "I1130 06:27:18.872099 2794 cuda_memory_manager.cc:105] CUDA memory pool is created on device 2 with size 67108864\n",
      "I1130 06:27:18.872104 2794 cuda_memory_manager.cc:105] CUDA memory pool is created on device 3 with size 67108864\n",
      "I1130 06:27:18.872108 2794 cuda_memory_manager.cc:105] CUDA memory pool is created on device 4 with size 67108864\n",
      "I1130 06:27:18.872112 2794 cuda_memory_manager.cc:105] CUDA memory pool is created on device 5 with size 67108864\n",
      "I1130 06:27:18.872117 2794 cuda_memory_manager.cc:105] CUDA memory pool is created on device 6 with size 67108864\n",
      "I1130 06:27:18.872121 2794 cuda_memory_manager.cc:105] CUDA memory pool is created on device 7 with size 67108864\n",
      "W1130 06:27:19.944789 2794 server.cc:204] failed to enable peer access for some device pairs\n",
      "I1130 06:27:19.957114 2794 model_repository_manager.cc:1022] loading: wdl:1\n",
      "I1130 06:27:20.086098 2794 hugectr.cc:1380] TRITONBACKEND_Initialize: hugectr\n",
      "I1130 06:27:20.086131 2794 hugectr.cc:1386] Triton TRITONBACKEND API version: 1.5\n",
      "I1130 06:27:20.086136 2794 hugectr.cc:1389] 'hugectr' TRITONBACKEND API version: 1.5\n",
      "I1130 06:27:20.086142 2794 hugectr.cc:1406] The HugeCTR backend Repository location: /usr/local/hugectr/backends/hugectr\n",
      "I1130 06:27:20.086148 2794 hugectr.cc:1414] The HugeCTR backend configuration: {\"cmdline\":{\"ps\":\"/wdl_infer/model/ps.json\"}}\n",
      "I1130 06:27:20.086214 2794 hugectr.cc:307] *****Parsing Parameter Server Configuration from /wdl_infer/model/ps.json\n",
      "I1130 06:27:20.086337 2794 hugectr.cc:325] Support 64-bit keys = 1\n",
      "I1130 06:27:20.086360 2794 hugectr.cc:336] CPU memory database -> type = disabled\n",
      "I1130 06:27:20.086369 2794 hugectr.cc:341] CPU memory database -> number of partitions = 8\n",
      "I1130 06:27:20.086376 2794 hugectr.cc:345] CPU memory database -> overflow policy = evict_oldest\n",
      "I1130 06:27:20.086383 2794 hugectr.cc:349] CPU memory database -> partition overflow margin = 1000000\n",
      "I1130 06:27:20.086403 2794 hugectr.cc:355] CPU memory database -> partition overflow resolution target = 0.8\n",
      "I1130 06:27:20.086412 2794 hugectr.cc:361] CPU memory database -> initial cache rate = 0.1\n",
      "I1130 06:27:20.086423 2794 hugectr.cc:367] CPU memory database -> update filters = [wurst0, .+]\n",
      "I1130 06:27:20.086434 2794 hugectr.cc:380] Distributed database -> type = redis_cluster\n",
      "I1130 06:27:20.086441 2794 hugectr.cc:385] Distributed database -> address = 127.0.0.1:7000,127.0.0.1:7001,127.0.0.1:7002\n",
      "I1130 06:27:20.086447 2794 hugectr.cc:389] Distributed database -> user name = default\n",
      "I1130 06:27:20.086454 2794 hugectr.cc:393] Distributed database -> password = <empty>\n",
      "I1130 06:27:20.086461 2794 hugectr.cc:398] Distributed database -> number of partitions = 8\n",
      "I1130 06:27:20.086468 2794 hugectr.cc:402] Distributed database -> max. batch size (GET) = 10000\n",
      "I1130 06:27:20.086474 2794 hugectr.cc:406] Distributed database -> max. batch size (SET) = 10000\n",
      "I1130 06:27:20.086481 2794 hugectr.cc:410] Distributed database -> overflow policy = evict_oldest\n",
      "I1130 06:27:20.086488 2794 hugectr.cc:414] Distributed database -> partition overflow margin = 10000000\n",
      "I1130 06:27:20.086495 2794 hugectr.cc:420] Distributed database -> partition overflow resolution target = 0.8\n",
      "I1130 06:27:20.086503 2794 hugectr.cc:426] Distributed database -> initial cache rate = 0.1\n",
      "I1130 06:27:20.086511 2794 hugectr.cc:432] Distributed database -> update filters = [wurst1, .+]\n",
      "I1130 06:27:20.086554 2794 hugectr.cc:445] Persistent database -> type = rocks_db\n",
      "I1130 06:27:20.086563 2794 hugectr.cc:450] Persistent database -> path = /wdl_infer/rocksdb\n",
      "I1130 06:27:20.086570 2794 hugectr.cc:454] Persistent database -> number of threads = 16\n",
      "I1130 06:27:20.086577 2794 hugectr.cc:458] Persistent database -> read-only = 0\n",
      "I1130 06:27:20.086583 2794 hugectr.cc:462] Persistent database -> max. batch size (GET) = 10000\n",
      "I1130 06:27:20.086590 2794 hugectr.cc:466] Persistent database -> max. batch size (SET) = 10000\n",
      "I1130 06:27:20.086597 2794 hugectr.cc:472] Persistent database -> update filters = [wurst2, .+]\n",
      "I1130 06:27:20.086622 2794 hugectr.cc:485] Update source -> type = kafka_message_queue\n",
      "I1130 06:27:20.086628 2794 hugectr.cc:490] Update source -> brokers = 127.0.0.1:9092\n",
      "I1130 06:27:20.086634 2794 hugectr.cc:494] Update source -> poll timeout = 500 ms\n",
      "I1130 06:27:20.086641 2794 hugectr.cc:498] Update source -> max. receive buffer size = 2000\n",
      "I1130 06:27:20.086648 2794 hugectr.cc:503] Update source -> max. batch size = 1000\n",
      "I1130 06:27:20.086654 2794 hugectr.cc:507] Update source -> failure backoff = 50 ms\n",
      "I1130 06:27:20.086662 2794 hugectr.cc:525] Model name = wdl\n",
      "I1130 06:27:20.086669 2794 hugectr.cc:532] Model 'wdl' -> network file = /wdl_infer/model/wdl/1/wdl.json\n",
      "I1130 06:27:20.086677 2794 hugectr.cc:538] Model 'wdl' -> max. batch size = 64\n",
      "I1130 06:27:20.086683 2794 hugectr.cc:543] Model 'wdl' -> dense model file = /wdl_infer/model/wdl/1/wdl_dense_20000.model\n",
      "I1130 06:27:20.086691 2794 hugectr.cc:548] Model 'wdl' -> sparse model files = [/wdl_infer/model/wdl/1/wdl0_sparse_20000.model, /wdl_infer/model/wdl/1/wdl1_sparse_20000.model]\n",
      "I1130 06:27:20.086699 2794 hugectr.cc:557] Model 'wdl' -> use GPU embedding cache = 1\n",
      "I1130 06:27:20.086709 2794 hugectr.cc:563] Model 'wdl' -> hit rate threshold = 0.9\n",
      "I1130 06:27:20.086717 2794 hugectr.cc:569] Model 'wdl' -> per model GPU cache = 0.5\n",
      "I1130 06:27:20.086734 2794 hugectr.cc:589] Model 'wdl' -> num. pool worker buffers = 4\n",
      "I1130 06:27:20.086742 2794 hugectr.cc:595] Model 'wdl' -> num. pool refresh buffers = 1\n",
      "I1130 06:27:20.086749 2794 hugectr.cc:601] Model 'wdl' -> cache refresh rate per iteration = 0.2\n",
      "I1130 06:27:20.086758 2794 hugectr.cc:609] Model 'wdl' -> deployed device list = [0]\n",
      "I1130 06:27:20.086768 2794 hugectr.cc:616] Model 'wdl' -> default value for each table = [0, 0]\n",
      "I1130 06:27:20.086784 2794 hugectr.cc:637] *****The HugeCTR Backend Parameter Server is creating... *****\n",
      "I1130 06:27:20.086794 2794 hugectr.cc:644] ***** Parameter Server(Int64) is creating... *****\n",
      "[HUGECTR][06:27:20][INFO][RANK0]: default_emb_vec_value is not specified using default: 0.000000\n",
      "[HUGECTR][06:27:20][INFO][RANK0]: default_emb_vec_value is not specified using default: 0.000000\n",
      "[HUGECTR][06:27:20][INFO][RANK0]: Creating RedisCluster backend...\n",
      "[HUGECTR][06:27:20][INFO][RANK0]: Connecting to Redis cluster via 127.0.0.1:7000 ...\n",
      "[HUGECTR][06:27:20][INFO][RANK0]: Connected to Redis database!\n",
      "[HUGECTR][06:27:20][INFO][RANK0]: Creating RocksDB backend...\n",
      "[HUGECTR][06:27:20][INFO][RANK0]: Connecting to RocksDB database...\n",
      "[HUGECTR][06:27:20][INFO][RANK0]: RocksDB /wdl_infer/rocksdb, found column family \"default\".\n",
      "[HUGECTR][06:27:20][INFO][RANK0]: RocksDB /wdl_infer/rocksdb, found column family \"hctr_et.wdl.sparse_embedding2\".\n",
      "[HUGECTR][06:27:20][INFO][RANK0]: Connected to RocksDB database!\n",
      "[HUGECTR][06:27:20][DEBUG][RANK0]: Redis partition hctr_et.wdl.sparse_embedding2/p0/v, query 0: Inserted 8240 pairs.\n",
      "[HUGECTR][06:27:21][DEBUG][RANK0]: Redis partition hctr_et.wdl.sparse_embedding2/p1/v, query 0: Inserted 8431 pairs.\n",
      "[HUGECTR][06:27:21][DEBUG][RANK0]: Redis partition hctr_et.wdl.sparse_embedding2/p2/v, query 0: Inserted 8292 pairs.\n",
      "[HUGECTR][06:27:21][DEBUG][RANK0]: Redis partition hctr_et.wdl.sparse_embedding2/p3/v, query 0: Inserted 8384 pairs.\n",
      "[HUGECTR][06:27:21][DEBUG][RANK0]: Redis partition hctr_et.wdl.sparse_embedding2/p4/v, query 0: Inserted 8400 pairs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HUGECTR][06:27:21][DEBUG][RANK0]: Redis partition hctr_et.wdl.sparse_embedding2/p5/v, query 0: Inserted 8379 pairs.\n",
      "[HUGECTR][06:27:21][DEBUG][RANK0]: Redis partition hctr_et.wdl.sparse_embedding2/p6/v, query 0: Inserted 8138 pairs.\n",
      "[HUGECTR][06:27:21][DEBUG][RANK0]: Redis partition hctr_et.wdl.sparse_embedding2/p7/v, query 0: Inserted 8168 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RedisCluster backend. Table: hctr_et.wdl.sparse_embedding2. Inserted 66432 / 66432 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: Table: hctr_et.wdl.sparse_embedding2; cached 66432 / 664320 embeddings in distributed database!\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 0: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 1: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 2: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 3: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 4: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 5: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 6: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 7: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 8: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 9: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 10: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 11: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 12: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 13: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 14: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 15: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 16: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 17: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 18: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 19: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 20: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 21: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 22: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 23: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 24: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 25: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 26: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 27: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 28: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 29: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 30: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 31: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 32: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 33: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 34: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 35: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 36: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 37: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 38: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 39: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 40: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 41: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 42: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 43: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 44: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 45: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 46: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 47: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 48: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 49: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 50: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 51: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 52: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 53: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 54: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 55: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 56: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 57: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 58: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 59: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 60: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 61: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 62: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 63: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 64: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 65: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding2, query 66: Inserted 4320 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: RocksDB backend. Table: hctr_et.wdl.sparse_embedding2. Inserted 664320 / 664320 pairs.\n",
      "[HUGECTR][06:27:21][INFO][RANK0]: Table: hctr_et.wdl.sparse_embedding2; cached 664320 embeddings in persistent database!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HUGECTR][06:27:21][DEBUG][RANK0]: Redis partition hctr_et.wdl.sparse_embedding1/p0/v, query 0: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:21][DEBUG][RANK0]: Redis partition hctr_et.wdl.sparse_embedding1/p0/v, query 1: Inserted 2755 pairs.\n",
      "[HUGECTR][06:27:22][DEBUG][RANK0]: Redis partition hctr_et.wdl.sparse_embedding1/p1/v, query 0: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][DEBUG][RANK0]: Redis partition hctr_et.wdl.sparse_embedding1/p1/v, query 1: Inserted 2852 pairs.\n",
      "[HUGECTR][06:27:22][DEBUG][RANK0]: Redis partition hctr_et.wdl.sparse_embedding1/p2/v, query 0: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][DEBUG][RANK0]: Redis partition hctr_et.wdl.sparse_embedding1/p2/v, query 1: Inserted 2693 pairs.\n",
      "[HUGECTR][06:27:22][DEBUG][RANK0]: Redis partition hctr_et.wdl.sparse_embedding1/p3/v, query 0: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][DEBUG][RANK0]: Redis partition hctr_et.wdl.sparse_embedding1/p3/v, query 1: Inserted 2939 pairs.\n",
      "[HUGECTR][06:27:22][DEBUG][RANK0]: Redis partition hctr_et.wdl.sparse_embedding1/p4/v, query 0: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][DEBUG][RANK0]: Redis partition hctr_et.wdl.sparse_embedding1/p4/v, query 1: Inserted 3054 pairs.\n",
      "[HUGECTR][06:27:22][DEBUG][RANK0]: Redis partition hctr_et.wdl.sparse_embedding1/p5/v, query 0: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][DEBUG][RANK0]: Redis partition hctr_et.wdl.sparse_embedding1/p5/v, query 1: Inserted 2948 pairs.\n",
      "[HUGECTR][06:27:22][DEBUG][RANK0]: Redis partition hctr_et.wdl.sparse_embedding1/p6/v, query 0: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][DEBUG][RANK0]: Redis partition hctr_et.wdl.sparse_embedding1/p6/v, query 1: Inserted 2952 pairs.\n",
      "[HUGECTR][06:27:22][DEBUG][RANK0]: Redis partition hctr_et.wdl.sparse_embedding1/p7/v, query 0: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][DEBUG][RANK0]: Redis partition hctr_et.wdl.sparse_embedding1/p7/v, query 1: Inserted 2857 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RedisCluster backend. Table: hctr_et.wdl.sparse_embedding1. Inserted 103050 / 103050 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: Table: hctr_et.wdl.sparse_embedding1; cached 103050 / 1030499 embeddings in distributed database!\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 0: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 1: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 2: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 3: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 4: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 5: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 6: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 7: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 8: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 9: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 10: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 11: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 12: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 13: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 14: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 15: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 16: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 17: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 18: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 19: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 20: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 21: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 22: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 23: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 24: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 25: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 26: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 27: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 28: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 29: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 30: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 31: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 32: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 33: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 34: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 35: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 36: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 37: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 38: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 39: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 40: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 41: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 42: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 43: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 44: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 45: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 46: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 47: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 48: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 49: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 50: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 51: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 52: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 53: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 54: Inserted 10000 pairs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 55: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 56: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 57: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:22][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 58: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 59: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 60: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 61: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 62: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 63: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 64: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 65: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 66: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 67: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 68: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 69: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 70: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 71: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 72: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 73: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 74: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 75: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 76: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 77: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 78: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 79: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 80: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 81: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 82: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 83: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 84: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 85: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 86: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 87: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 88: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 89: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 90: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 91: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 92: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 93: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 94: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 95: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 96: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 97: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 98: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 99: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 100: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 101: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 102: Inserted 10000 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB table hctr_et.wdl.sparse_embedding1, query 103: Inserted 499 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: RocksDB backend. Table: hctr_et.wdl.sparse_embedding1. Inserted 1030499 / 1030499 pairs.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: Table: hctr_et.wdl.sparse_embedding1; cached 1030499 embeddings in persistent database!\n",
      "[HUGECTR][06:27:23][DEBUG][RANK0]: Creating Kafka lifetime service.\n",
      "%3|1638253643.820|FAIL|rdkafka#consumer-1| [thrd:127.0.0.1:9092/bootstrap]: 127.0.0.1:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT)\n",
      "%3|1638253643.820|ERROR|rdkafka#consumer-1| [thrd:127.0.0.1:9092/bootstrap]: 1/1 brokers are down\n",
      "[HUGECTR][06:27:23][DEBUG][RANK0]: Real-time subscribers created!\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: Create embedding cache in device 0.\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: Use GPU embedding cache: True, cache size percentage: 0.500000\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: Configured cache hit rate threshold: 0.900000\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: Attempting to subscribe to Kafka topics <\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: ^hctr_et\\.wurst2\\..+$\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: ^hctr_et\\..+\\..+$\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: >\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: Attempting to subscribe to Kafka topics <\n",
      "%3|1638253643.820|FAIL|rdkafka#consumer-2| [thrd:127.0.0.1:9092/bootstrap]: 127.0.0.1:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT)\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: ^hctr_et\\.wurst1\\..+$\n",
      "%3|1638253643.820|ERROR|rdkafka#consumer-2| [thrd:127.0.0.1:9092/bootstrap]: 1/1 brokers are down\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: ^hctr_et\\..+\\..+$\n",
      "%3|1638253643.820|ERROR|rdkafka#consumer-2| [thrd:app]: rdkafka#consumer-2: 127.0.0.1:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT)\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: >\n",
      "%3|1638253643.821|ERROR|rdkafka#consumer-1| [thrd:app]: rdkafka#consumer-1: 127.0.0.1:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT)\n",
      "I1130 06:27:23.879531 2794 hugectr.cc:656] *****The HugeCTR Backend Backend created the Parameter Server successfully! *****\n",
      "I1130 06:27:23.885066 2794 hugectr.cc:1470] TRITONBACKEND_ModelInitialize: wdl (version 1)\n",
      "I1130 06:27:23.885077 2794 hugectr.cc:1480] Repository location: /wdl_infer/model/wdl\n",
      "I1130 06:27:23.885084 2794 hugectr.cc:1493] backend configuration in mode: {\"cmdline\":{\"ps\":\"/wdl_infer/model/ps.json\"}}\n",
      "I1130 06:27:23.886459 2794 hugectr.cc:880] Verifying model configuration: {\n",
      "    \"name\": \"wdl\",\n",
      "    \"platform\": \"\",\n",
      "    \"backend\": \"hugectr\",\n",
      "    \"version_policy\": {\n",
      "        \"latest\": {\n",
      "            \"num_versions\": 1\n",
      "        }\n",
      "    },\n",
      "    \"max_batch_size\": 64,\n",
      "    \"input\": [\n",
      "        {\n",
      "            \"name\": \"DES\",\n",
      "            \"data_type\": \"TYPE_FP32\",\n",
      "            \"format\": \"FORMAT_NONE\",\n",
      "            \"dims\": [\n",
      "                -1\n",
      "            ],\n",
      "            \"is_shape_tensor\": false,\n",
      "            \"allow_ragged_batch\": false\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"CATCOLUMN\",\n",
      "            \"data_type\": \"TYPE_INT64\",\n",
      "            \"format\": \"FORMAT_NONE\",\n",
      "            \"dims\": [\n",
      "                -1\n",
      "            ],\n",
      "            \"is_shape_tensor\": false,\n",
      "            \"allow_ragged_batch\": false\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"ROWINDEX\",\n",
      "            \"data_type\": \"TYPE_INT32\",\n",
      "            \"format\": \"FORMAT_NONE\",\n",
      "            \"dims\": [\n",
      "                -1\n",
      "            ],\n",
      "            \"is_shape_tensor\": false,\n",
      "            \"allow_ragged_batch\": false\n",
      "        }\n",
      "    ],\n",
      "    \"output\": [\n",
      "        {\n",
      "            \"name\": \"OUTPUT0\",\n",
      "            \"data_type\": \"TYPE_FP32\",\n",
      "            \"dims\": [\n",
      "                -1\n",
      "            ],\n",
      "            \"label_filename\": \"\",\n",
      "            \"is_shape_tensor\": false\n",
      "        }\n",
      "    ],\n",
      "    \"batch_input\": [],\n",
      "    \"batch_output\": [],\n",
      "    \"optimization\": {\n",
      "        \"priority\": \"PRIORITY_DEFAULT\",\n",
      "        \"input_pinned_memory\": {\n",
      "            \"enable\": true\n",
      "        },\n",
      "        \"output_pinned_memory\": {\n",
      "            \"enable\": true\n",
      "        },\n",
      "        \"gather_kernel_buffer_threshold\": 0,\n",
      "        \"eager_batching\": false\n",
      "    },\n",
      "    \"instance_group\": [\n",
      "        {\n",
      "            \"name\": \"wdl_0\",\n",
      "            \"kind\": \"KIND_GPU\",\n",
      "            \"count\": 1,\n",
      "            \"gpus\": [\n",
      "                0\n",
      "            ],\n",
      "            \"secondary_devices\": [],\n",
      "            \"profile\": [],\n",
      "            \"passive\": false,\n",
      "            \"host_policy\": \"\"\n",
      "        }\n",
      "    ],\n",
      "    \"default_model_filename\": \"\",\n",
      "    \"cc_model_filenames\": {},\n",
      "    \"metric_tags\": {},\n",
      "    \"parameters\": {\n",
      "        \"embedding_vector_size\": {\n",
      "            \"string_value\": \"128\"\n",
      "        },\n",
      "        \"gpucacheper\": {\n",
      "            \"string_value\": \"0.5\"\n",
      "        },\n",
      "        \"des_feature_num\": {\n",
      "            \"string_value\": \"13\"\n",
      "        },\n",
      "        \"hit_rate_threshold\": {\n",
      "            \"string_value\": \"0.8\"\n",
      "        },\n",
      "        \"gpucache\": {\n",
      "            \"string_value\": \"true\"\n",
      "        },\n",
      "        \"embeddingkey_long_type\": {\n",
      "            \"string_value\": \"true\"\n",
      "        },\n",
      "        \"slots\": {\n",
      "            \"string_value\": \"28\"\n",
      "        },\n",
      "        \"config\": {\n",
      "            \"string_value\": \"/wdl_infer/model/wdl/1/wdl.json\"\n",
      "        },\n",
      "        \"cat_feature_num\": {\n",
      "            \"string_value\": \"28\"\n",
      "        },\n",
      "        \"label_dim\": {\n",
      "            \"string_value\": \"1\"\n",
      "        },\n",
      "        \"max_nnz\": {\n",
      "            \"string_value\": \"2\"\n",
      "        }\n",
      "    },\n",
      "    \"model_warmup\": []\n",
      "}\n",
      "I1130 06:27:23.886555 2794 hugectr.cc:953] The model configuration: {\n",
      "    \"name\": \"wdl\",\n",
      "    \"platform\": \"\",\n",
      "    \"backend\": \"hugectr\",\n",
      "    \"version_policy\": {\n",
      "        \"latest\": {\n",
      "            \"num_versions\": 1\n",
      "        }\n",
      "    },\n",
      "    \"max_batch_size\": 64,\n",
      "    \"input\": [\n",
      "        {\n",
      "            \"name\": \"DES\",\n",
      "            \"data_type\": \"TYPE_FP32\",\n",
      "            \"format\": \"FORMAT_NONE\",\n",
      "            \"dims\": [\n",
      "                -1\n",
      "            ],\n",
      "            \"is_shape_tensor\": false,\n",
      "            \"allow_ragged_batch\": false\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"CATCOLUMN\",\n",
      "            \"data_type\": \"TYPE_INT64\",\n",
      "            \"format\": \"FORMAT_NONE\",\n",
      "            \"dims\": [\n",
      "                -1\n",
      "            ],\n",
      "            \"is_shape_tensor\": false,\n",
      "            \"allow_ragged_batch\": false\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"ROWINDEX\",\n",
      "            \"data_type\": \"TYPE_INT32\",\n",
      "            \"format\": \"FORMAT_NONE\",\n",
      "            \"dims\": [\n",
      "                -1\n",
      "            ],\n",
      "            \"is_shape_tensor\": false,\n",
      "            \"allow_ragged_batch\": false\n",
      "        }\n",
      "    ],\n",
      "    \"output\": [\n",
      "        {\n",
      "            \"name\": \"OUTPUT0\",\n",
      "            \"data_type\": \"TYPE_FP32\",\n",
      "            \"dims\": [\n",
      "                -1\n",
      "            ],\n",
      "            \"label_filename\": \"\",\n",
      "            \"is_shape_tensor\": false\n",
      "        }\n",
      "    ],\n",
      "    \"batch_input\": [],\n",
      "    \"batch_output\": [],\n",
      "    \"optimization\": {\n",
      "        \"priority\": \"PRIORITY_DEFAULT\",\n",
      "        \"input_pinned_memory\": {\n",
      "            \"enable\": true\n",
      "        },\n",
      "        \"output_pinned_memory\": {\n",
      "            \"enable\": true\n",
      "        },\n",
      "        \"gather_kernel_buffer_threshold\": 0,\n",
      "        \"eager_batching\": false\n",
      "    },\n",
      "    \"instance_group\": [\n",
      "        {\n",
      "            \"name\": \"wdl_0\",\n",
      "            \"kind\": \"KIND_GPU\",\n",
      "            \"count\": 1,\n",
      "            \"gpus\": [\n",
      "                0\n",
      "            ],\n",
      "            \"secondary_devices\": [],\n",
      "            \"profile\": [],\n",
      "            \"passive\": false,\n",
      "            \"host_policy\": \"\"\n",
      "        }\n",
      "    ],\n",
      "    \"default_model_filename\": \"\",\n",
      "    \"cc_model_filenames\": {},\n",
      "    \"metric_tags\": {},\n",
      "    \"parameters\": {\n",
      "        \"embedding_vector_size\": {\n",
      "            \"string_value\": \"128\"\n",
      "        },\n",
      "        \"gpucacheper\": {\n",
      "            \"string_value\": \"0.5\"\n",
      "        },\n",
      "        \"des_feature_num\": {\n",
      "            \"string_value\": \"13\"\n",
      "        },\n",
      "        \"hit_rate_threshold\": {\n",
      "            \"string_value\": \"0.8\"\n",
      "        },\n",
      "        \"gpucache\": {\n",
      "            \"string_value\": \"true\"\n",
      "        },\n",
      "        \"embeddingkey_long_type\": {\n",
      "            \"string_value\": \"true\"\n",
      "        },\n",
      "        \"slots\": {\n",
      "            \"string_value\": \"28\"\n",
      "        },\n",
      "        \"config\": {\n",
      "            \"string_value\": \"/wdl_infer/model/wdl/1/wdl.json\"\n",
      "        },\n",
      "        \"cat_feature_num\": {\n",
      "            \"string_value\": \"28\"\n",
      "        },\n",
      "        \"label_dim\": {\n",
      "            \"string_value\": \"1\"\n",
      "        },\n",
      "        \"max_nnz\": {\n",
      "            \"string_value\": \"2\"\n",
      "        }\n",
      "    },\n",
      "    \"model_warmup\": []\n",
      "}\n",
      "I1130 06:27:23.886638 2794 hugectr.cc:989] slots set = 28\n",
      "I1130 06:27:23.886646 2794 hugectr.cc:994] desene number = 13\n",
      "I1130 06:27:23.886652 2794 hugectr.cc:999] cat_feature number = 28\n",
      "I1130 06:27:23.886659 2794 hugectr.cc:1009] embedding size = 128\n",
      "I1130 06:27:23.886665 2794 hugectr.cc:1014] maxnnz = 2\n",
      "I1130 06:27:23.886672 2794 hugectr.cc:1029] HugeCTR model config path = /wdl_infer/model/wdl/1/wdl.json\n",
      "I1130 06:27:23.886681 2794 hugectr.cc:1049] support gpu cache = 1\n",
      "I1130 06:27:23.886696 2794 hugectr.cc:1068] gpu cache per = 0.5\n",
      "I1130 06:27:23.886704 2794 hugectr.cc:1081] hit-rate threshold = 0.8\n",
      "I1130 06:27:23.886728 2794 hugectr.cc:1094] Label dim = 1\n",
      "I1130 06:27:23.886735 2794 hugectr.cc:1099] support 64-bit embedding key = 1\n",
      "I1130 06:27:23.886742 2794 hugectr.cc:1110] Model_Inference_Para.max_batchsize: 64\n",
      "I1130 06:27:23.886748 2794 hugectr.cc:1113] max_batch_size in model config.pbtxt is 64\n",
      "I1130 06:27:23.886755 2794 hugectr.cc:1153] ******Creating Embedding Cache for model wdl in device 0\n",
      "I1130 06:27:23.886763 2794 hugectr.cc:1178] ******Creating Embedding Cache for model wdl successfully\n",
      "I1130 06:27:23.890556 2794 hugectr.cc:1557] TRITONBACKEND_ModelInstanceInitialize: wdl_0 (device 0)\n",
      "I1130 06:27:23.890571 2794 hugectr.cc:1287] Triton Model Instance Initialization on device 0\n",
      "I1130 06:27:23.890594 2794 hugectr.cc:1296] Dense Feature buffer allocation: \n",
      "I1130 06:27:23.890650 2794 hugectr.cc:1302] Categorical Feature buffer allocation: \n",
      "I1130 06:27:23.890710 2794 hugectr.cc:1317] Categorical Row Index buffer allocation: \n",
      "I1130 06:27:23.890740 2794 hugectr.cc:1323] Predict result buffer allocation: \n",
      "I1130 06:27:23.890769 2794 hugectr.cc:1577] ******Loading HugeCTR Model******\n",
      "I1130 06:27:23.890794 2794 hugectr.cc:1340] The model origin json configuration file path is: /wdl_infer/model/wdl/1/wdl.json\n",
      "[HUGECTR][06:27:23][INFO][RANK0]: Global seed is 3342039900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%3|1638253644.819|FAIL|rdkafka#consumer-1| [thrd:127.0.0.1:9092/bootstrap]: 127.0.0.1:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT, 1 identical error(s) suppressed)\n",
      "%3|1638253644.819|ERROR|rdkafka#consumer-1| [thrd:app]: rdkafka#consumer-1: 127.0.0.1:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT, 1 identical error(s) suppressed)\n",
      "%3|1638253644.820|FAIL|rdkafka#consumer-2| [thrd:127.0.0.1:9092/bootstrap]: 127.0.0.1:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT, 1 identical error(s) suppressed)\n",
      "%3|1638253644.820|ERROR|rdkafka#consumer-2| [thrd:app]: rdkafka#consumer-2: 127.0.0.1:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT, 1 identical error(s) suppressed)\n",
      "[HUGECTR][06:27:25][WARNING][RANK0]: Peer-to-peer access cannot be fully enabled.\n",
      "[HUGECTR][06:27:25][INFO][RANK0]: Start all2all warmup\n",
      "[HUGECTR][06:27:25][INFO][RANK0]: End all2all warmup\n",
      "[HUGECTR][06:27:25][INFO][RANK0]: Model name: wdl\n",
      "[HUGECTR][06:27:25][INFO][RANK0]: Use mixed precision: False\n",
      "[HUGECTR][06:27:25][INFO][RANK0]: Use cuda graph: True\n",
      "[HUGECTR][06:27:25][INFO][RANK0]: Max batchsize: 64\n",
      "[HUGECTR][06:27:25][INFO][RANK0]: Use I64 input key: True\n",
      "[HUGECTR][06:27:25][INFO][RANK0]: start create embedding for inference\n",
      "[HUGECTR][06:27:25][INFO][RANK0]: sparse_input name wide_data\n",
      "[HUGECTR][06:27:25][INFO][RANK0]: sparse_input name deep_data\n",
      "[HUGECTR][06:27:25][INFO][RANK0]: create embedding for inference success\n",
      "[HUGECTR][06:27:25][INFO][RANK0]: Inference stage skip BinaryCrossEntropyLoss layer, replaced by Sigmoid layer\n",
      "I1130 06:27:25.687591 2794 hugectr.cc:1345] ******Loading HugeCTR model successfully\n",
      "I1130 06:27:25.687862 2794 model_repository_manager.cc:1183] successfully loaded 'wdl' version 1\n",
      "I1130 06:27:25.688034 2794 server.cc:519] \n",
      "+------------------+------+\n",
      "| Repository Agent | Path |\n",
      "+------------------+------+\n",
      "+------------------+------+\n",
      "\n",
      "I1130 06:27:25.688079 2794 server.cc:546] \n",
      "+---------+---------------------------------+---------------------------------+\n",
      "| Backend | Path                            | Config                          |\n",
      "+---------+---------------------------------+---------------------------------+\n",
      "| hugectr | /usr/local/hugectr/backends/hug | {\"cmdline\":{\"ps\":\"/wdl_infer/mo |\n",
      "|         | ectr/libtriton_hugectr.so       | del/ps.json\"}}                  |\n",
      "+---------+---------------------------------+---------------------------------+\n",
      "\n",
      "I1130 06:27:25.688130 2794 server.cc:589] \n",
      "+-------+---------+--------+\n",
      "| Model | Version | Status |\n",
      "+-------+---------+--------+\n",
      "| wdl   | 1       | READY  |\n",
      "+-------+---------+--------+\n",
      "\n",
      "I1130 06:27:25.688270 2794 tritonserver.cc:1836] \n",
      "+----------------------------------+------------------------------------------+\n",
      "| Option                           | Value                                    |\n",
      "+----------------------------------+------------------------------------------+\n",
      "| server_id                        | triton                                   |\n",
      "| server_version                   | 2.14.0                                   |\n",
      "| server_extensions                | classification sequence model_repository |\n",
      "|                                  |  model_repository(unload_dependents) sch |\n",
      "|                                  | edule_policy model_configuration system_ |\n",
      "|                                  | shared_memory cuda_shared_memory binary_ |\n",
      "|                                  | tensor_data statistics                   |\n",
      "| model_repository_path[0]         | /wdl_infer/model/                        |\n",
      "| model_control_mode               | MODE_EXPLICIT                            |\n",
      "| startup_models_0                 | wdl                                      |\n",
      "| strict_model_config              | 1                                        |\n",
      "| rate_limit                       | OFF                                      |\n",
      "| pinned_memory_pool_byte_size     | 268435456                                |\n",
      "| cuda_memory_pool_byte_size{0}    | 67108864                                 |\n",
      "| cuda_memory_pool_byte_size{1}    | 67108864                                 |\n",
      "| cuda_memory_pool_byte_size{2}    | 67108864                                 |\n",
      "| cuda_memory_pool_byte_size{3}    | 67108864                                 |\n",
      "| cuda_memory_pool_byte_size{4}    | 67108864                                 |\n",
      "| cuda_memory_pool_byte_size{5}    | 67108864                                 |\n",
      "| cuda_memory_pool_byte_size{6}    | 67108864                                 |\n",
      "| cuda_memory_pool_byte_size{7}    | 67108864                                 |\n",
      "| min_supported_compute_capability | 6.0                                      |\n",
      "| strict_readiness                 | 1                                        |\n",
      "| exit_timeout                     | 30                                       |\n",
      "+----------------------------------+------------------------------------------+\n",
      "\n",
      "I1130 06:27:25.689686 2794 grpc_server.cc:4111] Started GRPCInferenceService at 0.0.0.0:8001\n",
      "I1130 06:27:25.690183 2794 http_server.cc:2803] Started HTTPService at 0.0.0.0:8000\n",
      "I1130 06:27:25.731722 2794 http_server.cc:162] Started Metrics Service at 0.0.0.0:8002\n",
      "^C\n",
      "Signal (2) received.\n",
      "I1130 06:27:51.853888 2794 server.cc:249] Waiting for in-flight requests to complete.\n",
      "I1130 06:27:51.853905 2794 model_repository_manager.cc:1055] unloading: wdl:1\n",
      "I1130 06:27:51.854076 2794 server.cc:264] Timeout 30: Found 1 live models and 0 in-flight non-inference requests\n",
      "I1130 06:27:51.854411 2794 hugectr.cc:1591] TRITONBACKEND_ModelInstanceFinalize: delete instance state\n",
      "I1130 06:27:51.879884 2794 hugectr.cc:1542] TRITONBACKEND_ModelFinalize: delete model state\n",
      "I1130 06:27:51.879912 2794 hugectr.cc:1455] TRITONBACKEND_Backend Finalize: HugectrBackend\n"
     ]
    }
   ],
   "source": [
    "!tritonserver --model-repository=/wdl_infer/model/ --load-model=wdl \\\n",
    "    --model-control-mode=explicit \\\n",
    "    --backend-directory=/usr/local/hugectr/backends \\\n",
    "    --backend-config=hugectr,ps=/wdl_infer/model/ps.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b271b13",
   "metadata": {},
   "source": [
    "### 3.1 Check Triton server status if deploy Wide&Deep model successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3211a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*   Trying 127.0.0.1:8000...\r\n",
      "* TCP_NODELAY set\r\n",
      "* Connected to localhost (127.0.0.1) port 8000 (#0)\r\n",
      "> GET /v2/health/ready HTTP/1.1\r\n",
      "\r\n",
      "> Host: localhost:8000\r\n",
      "\r\n",
      "> User-Agent: curl/7.68.0\r\n",
      "\r\n",
      "> Accept: */*\r\n",
      "\r\n",
      "> \r\n",
      "\r\n",
      "* Mark bundle as not supporting multiuse\r\n",
      "< HTTP/1.1 200 OK\r\n",
      "\r\n",
      "< Content-Length: 0\r\n",
      "\r\n",
      "< Content-Type: text/plain\r\n",
      "\r\n",
      "< \r\n",
      "\r\n",
      "* Connection #0 to host localhost left intact\r\n"
     ]
    }
   ],
   "source": [
    "!curl -v localhost:8000/v2/health/ready"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4467413",
   "metadata": {},
   "source": [
    "# 4. Prepare Inference Request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc8892d",
   "metadata": {},
   "source": [
    "### 4.1 Read validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8903c9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 645762\r\n",
      "-rw-r--r-- 1 root root        32 Nov 29 05:27 _file_list.txt\r\n",
      "-rw-r--r-- 1 root root   8554464 Nov 29 05:27 _hugectr.keyset\r\n",
      "-rw-r--r-- 1 root root     22726 Nov 29 05:27 _metadata\r\n",
      "-rw-r--r-- 1 root root      1509 Nov 29 05:27 _metadata.json\r\n",
      "-rw-r--r-- 1 root root 142825257 Nov 29 05:27 part_0.parquet\r\n",
      "-rw-r--r-- 1 root root     21459 Nov 29 05:27 schema.pbtxt\r\n",
      "drwxr-xr-x 2 root root      4096 Nov 29 05:26 temp-parquet-after-conversion\r\n",
      "-rw-r--r-- 1 root root 509766965 Nov 29 03:50 test.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l /wdl_train/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a06239c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(\"/wdl_train/val/part_0.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27e23171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>I10</th>\n",
       "      <th>...</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.055886</td>\n",
       "      <td>-0.548824</td>\n",
       "      <td>-0.272394</td>\n",
       "      <td>-0.157301</td>\n",
       "      <td>-0.224758</td>\n",
       "      <td>-0.206385</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>0.096421</td>\n",
       "      <td>-0.543133</td>\n",
       "      <td>-0.470383</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3856</td>\n",
       "      <td>4891</td>\n",
       "      <td>4119</td>\n",
       "      <td>143</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.059432</td>\n",
       "      <td>-0.380376</td>\n",
       "      <td>-0.272394</td>\n",
       "      <td>5.629719</td>\n",
       "      <td>-0.224758</td>\n",
       "      <td>-0.206385</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.279201</td>\n",
       "      <td>-0.253935</td>\n",
       "      <td>-0.470383</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.059432</td>\n",
       "      <td>-0.539315</td>\n",
       "      <td>-0.594327</td>\n",
       "      <td>-0.142386</td>\n",
       "      <td>-0.193763</td>\n",
       "      <td>-0.206385</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.023569</td>\n",
       "      <td>-0.687732</td>\n",
       "      <td>-0.470383</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2439</td>\n",
       "      <td>41980</td>\n",
       "      <td>349</td>\n",
       "      <td>3549</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.059432</td>\n",
       "      <td>-0.463242</td>\n",
       "      <td>-0.594327</td>\n",
       "      <td>-0.097641</td>\n",
       "      <td>-0.209261</td>\n",
       "      <td>-0.206385</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.219206</td>\n",
       "      <td>-0.687732</td>\n",
       "      <td>-0.470383</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4024</td>\n",
       "      <td>3677</td>\n",
       "      <td>4287</td>\n",
       "      <td>565</td>\n",
       "      <td>306</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.022145</td>\n",
       "      <td>-0.509429</td>\n",
       "      <td>-0.379705</td>\n",
       "      <td>-0.151335</td>\n",
       "      <td>-0.162767</td>\n",
       "      <td>-0.206385</td>\n",
       "      <td>-0.064249</td>\n",
       "      <td>-0.281810</td>\n",
       "      <td>-0.470833</td>\n",
       "      <td>-0.470383</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>40847</td>\n",
       "      <td>3862</td>\n",
       "      <td>41562</td>\n",
       "      <td>1066</td>\n",
       "      <td>132</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         I1        I2        I3        I4        I5        I6        I7  \\\n",
       "0 -0.055886 -0.548824 -0.272394 -0.157301 -0.224758 -0.206385 -0.064249   \n",
       "1 -0.059432 -0.380376 -0.272394  5.629719 -0.224758 -0.206385 -0.064249   \n",
       "2 -0.059432 -0.539315 -0.594327 -0.142386 -0.193763 -0.206385 -0.064249   \n",
       "3 -0.059432 -0.463242 -0.594327 -0.097641 -0.209261 -0.206385 -0.064249   \n",
       "4  0.022145 -0.509429 -0.379705 -0.151335 -0.162767 -0.206385 -0.064249   \n",
       "\n",
       "         I8        I9       I10  ...  C18  C19    C20   C21    C22   C23  \\\n",
       "0  0.096421 -0.543133 -0.470383  ...    1    1   3856  4891   4119   143   \n",
       "1 -0.279201 -0.253935 -0.470383  ...    2    1      2     2      2     0   \n",
       "2 -0.023569 -0.687732 -0.470383  ...    1    1      0  2439  41980   349   \n",
       "3 -0.219206 -0.687732 -0.470383  ...    1    1   4024  3677   4287   565   \n",
       "4 -0.281810 -0.470833 -0.470383  ...    2    3  40847  3862  41562  1066   \n",
       "\n",
       "    C24  C25  C26  label  \n",
       "0    50    1    1    0.0  \n",
       "1   327    2    1    0.0  \n",
       "2  3549    6    1    1.0  \n",
       "3   306    4    1    0.0  \n",
       "4   132    2    1    0.0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cec3bd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10).to_csv('/wdl_infer/infer_test.csv', sep=',', index=False,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae7fc71",
   "metadata": {},
   "source": [
    "## 4.2 Follow the Triton requirements to generate inference requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54de3154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /wdl_infer/wdl2predict.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile '/wdl_infer/wdl2predict.py'\n",
    "from tritonclient.utils import *\n",
    "import tritonclient.http  as httpclient\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "model_name = 'wdl'\n",
    "CATEGORICAL_COLUMNS=[\"C1_C2\",\"C3_C4\"]+[\"C\" + str(x) for x in range(1, 27)]\n",
    "CONTINUOUS_COLUMNS=[\"I\" + str(x) for x in range(1, 14)]\n",
    "LABEL_COLUMNS = ['label']\n",
    "emb_size_array = [278018, 415262,249058, 19561, 14212, 6890, 18592, 4, 6356, 1254, 52, 226170, 80508, 72308, 11, 2169, 7597, 61, 4, 923, 15, 249619, 168974, 243480, 68212, 9169, 75, 34]\n",
    "shift = np.insert(np.cumsum(emb_size_array), 0, 0)[:-1]\n",
    "test_df=pd.read_csv(\"/wdl_infer/infer_test.csv\",sep=',')\n",
    "\n",
    "\n",
    "\n",
    "with httpclient.InferenceServerClient(\"localhost:8000\") as client:\n",
    "    dense_features = np.array([list(test_df[CONTINUOUS_COLUMNS].values.flatten())],dtype='float32')\n",
    "    embedding_columns = np.array([list((test_df[CATEGORICAL_COLUMNS]+shift).values.flatten())],dtype='int64')\n",
    "    row_ptrs = np.array([list(range(0,21))+list(range(0,261))],dtype='int32')\n",
    "    \n",
    "    inputs = [\n",
    "        httpclient.InferInput(\"DES\", dense_features.shape,\n",
    "                              np_to_triton_dtype(dense_features.dtype)),\n",
    "        httpclient.InferInput(\"CATCOLUMN\", embedding_columns.shape,\n",
    "                              np_to_triton_dtype(embedding_columns.dtype)),\n",
    "        httpclient.InferInput(\"ROWINDEX\", row_ptrs.shape,\n",
    "                              np_to_triton_dtype(row_ptrs.dtype)),\n",
    "\n",
    "    ]\n",
    "\n",
    "    inputs[0].set_data_from_numpy(dense_features)\n",
    "    inputs[1].set_data_from_numpy(embedding_columns)\n",
    "    inputs[2].set_data_from_numpy(row_ptrs)\n",
    "    outputs = [\n",
    "        httpclient.InferRequestedOutput(\"OUTPUT0\")\n",
    "    ]\n",
    "\n",
    "    response = client.infer(model_name,\n",
    "                            inputs,\n",
    "                            request_id=str(1),\n",
    "                            outputs=outputs)\n",
    "\n",
    "    result = response.get_response()\n",
    "    print(result)\n",
    "    print(\"Prediction Result:\")\n",
    "    print(response.as_numpy(\"OUTPUT0\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3474067b",
   "metadata": {},
   "source": [
    "## 4.3 Send requests to Triton Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c575b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '1', 'model_name': 'wdl', 'model_version': '1', 'parameters': {'NumSample': 10, 'DeviceID': 0}, 'outputs': [{'name': 'OUTPUT0', 'datatype': 'FP32', 'shape': [10], 'parameters': {'binary_data_size': 40}}]}\r\n",
      "Prediction Result:\r\n",
      "[0.03392845 0.02259001 0.00255735 0.00028795 0.00226125 0.02724345\r\n",
      " 0.00389859 0.00180469 0.03567842 0.00802261]\r\n"
     ]
    }
   ],
   "source": [
    "!python3 /wdl_infer/wdl2predict.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
